{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "G_Chaudhari VQVAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbueFvtKpV+t+UrPrTMY0+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GCioa123/PatternFlow/blob/topic-recognition/G_Chaudhari_VQVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTb4lLSuWDRe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6rAw4V2IYA8",
        "outputId": "613e5256-068f-44c0-a78a-60438eb1c79d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xep4-xdNMMj"
      },
      "source": [
        "import os\n",
        "\n",
        "#Loading the data\n",
        "\n",
        "input_train_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_train/' #this you have give your seg_train folder path\n",
        "target_train_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_seg_train/' #seg_val folder path\n",
        "input_val_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_validate/' #this you have give your seg_train folder path\n",
        "target_val_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_seg_validate/' #seg_val folder path\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mocffPMdPb_-",
        "outputId": "473e6147-1eac-415b-80ca-106c25704a6b"
      },
      "source": [
        "# Extract data to train and test data sets\n",
        "img_size = (256, 256)\n",
        "num_classes = 4\n",
        "batch_size = 3\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_train_dir, fname)\n",
        "        for fname in os.listdir(input_train_dir)\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_train_dir, fname)\n",
        "        for fname in os.listdir(target_train_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_val_dir, fname)\n",
        "        for fname in os.listdir(input_val_dir)\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "val_target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_val_dir, fname)\n",
        "        for fname in os.listdir(target_val_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths))\n",
        "\n",
        "# for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
        "#     print(input_path, \"|\", target_path)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PClDjJN7Ncxi"
      },
      "source": [
        "#vectoriser\n",
        "\n",
        "class VectorQuantizer(layers.Layer):\n",
        "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.beta = (\n",
        "            beta  # This parameter is best kept between [0.25, 2] as per the paper.\n",
        "        )\n",
        "\n",
        "        # Initialize the embeddings which we will quantize.\n",
        "        w_init = tf.random_uniform_initializer()\n",
        "        self.embeddings = tf.Variable(\n",
        "            initial_value=w_init(\n",
        "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
        "            ),\n",
        "            trainable=True,\n",
        "            name=\"embeddings_vqvae\",\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        # Calculate the input shape of the inputs and\n",
        "        # then flatten the inputs keeping `embedding_dim` intact.\n",
        "        input_shape = tf.shape(x)\n",
        "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
        "\n",
        "        # Quantization.\n",
        "        encoding_indices = self.get_code_indices(flattened)\n",
        "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
        "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
        "        quantized = tf.reshape(quantized, input_shape)\n",
        "\n",
        "        # Calculate vector quantization loss and add that to the layer. You can learn more\n",
        "        # about adding losses to different layers here:\n",
        "        # https://keras.io/guides/making_new_layers_and_models_via_subclassing/. Check\n",
        "        # the original paper to get a handle on the formulation of the loss function.\n",
        "        commitment_loss = self.beta * tf.reduce_mean(\n",
        "            (tf.stop_gradient(quantized) - x) ** 2\n",
        "        )\n",
        "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
        "        self.add_loss(commitment_loss + codebook_loss)\n",
        "\n",
        "        # Straight-through estimator.\n",
        "        quantized = x + tf.stop_gradient(quantized - x)\n",
        "        return quantized\n",
        "\n",
        "    def get_code_indices(self, flattened_inputs):\n",
        "        # Calculate L2-normalized distance between the inputs and the codes.\n",
        "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
        "        distances = (\n",
        "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
        "            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
        "            - 2 * similarity\n",
        "        )\n",
        "\n",
        "        # Derive the indices for minimum distances.\n",
        "        encoding_indices = tf.argmin(distances, axis=1)\n",
        "        return encoding_indices"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23s4Qw1dNant"
      },
      "source": [
        "#encoder \n",
        "def get_encoder(latent_dim=16):\n",
        "    encoder_inputs = keras.Input(shape=(256, 256, 3))\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        encoder_inputs\n",
        "    )\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n",
        "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8K2fEzwNep0"
      },
      "source": [
        "#decoder\n",
        "def get_decoder(latent_dim=16):\n",
        "    latent_inputs = keras.Input(shape=get_encoder().output.shape[1:])\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        latent_inputs\n",
        "    )\n",
        "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(1, 3, padding=\"same\")(x)\n",
        "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my_o9U8PNgZ7",
        "outputId": "5f4d90e2-4590-42b9-c287-ce035d180835"
      },
      "source": [
        "#Stand-alone VQ-VAE\n",
        "def get_vqvae(latent_dim=16, num_embeddings=64):\n",
        "    vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n",
        "    encoder = get_encoder(latent_dim)\n",
        "    decoder = get_decoder(latent_dim)\n",
        "    inputs = keras.Input(shape=(256, 256, 3))\n",
        "    encoder_outputs = encoder(inputs)\n",
        "    quantized_latents = vq_layer(encoder_outputs)\n",
        "    reconstructions = decoder(quantized_latents)\n",
        "    return keras.Model(inputs, reconstructions, name=\"vq_vae\")\n",
        "\n",
        "\n",
        "get_vqvae().summary()\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vq_vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 64, 64, 16)        20432     \n",
            "                                                                 \n",
            " vector_quantizer (VectorQua  (None, 64, 64, 16)       1024      \n",
            " ntizer)                                                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 256, 256, 1)       28033     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,489\n",
            "Trainable params: 49,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdRnn0YhPM_f"
      },
      "source": [
        "#VQ-VAE Trainer\n",
        "class VQVAETrainer(keras.models.Model):\n",
        "    def __init__(self, train_variance, latent_dim=32, num_embeddings=128, **kwargs):\n",
        "        super(VQVAETrainer, self).__init__(**kwargs)\n",
        "        self.train_variance = train_variance\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "\n",
        "        self.vqvae = get_vqvae(self.latent_dim, self.num_embeddings)\n",
        "\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.vq_loss_tracker = keras.metrics.Mean(name=\"vq_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.vq_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, x):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Outputs from the VQ-VAE.\n",
        "            reconstructions = self.vqvae(x)\n",
        "\n",
        "            # Calculate the losses.\n",
        "            reconstruction_loss = (\n",
        "                tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance\n",
        "            )\n",
        "            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
        "\n",
        "        # Backpropagation.\n",
        "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
        "\n",
        "        # Loss tracking.\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
        "\n",
        "        # Log results.\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
        "        }"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jukvz4ZVRMKZ"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "\n",
        "class oasis_data(keras.utils.Sequence):\n",
        "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = np.array(load_img(path, target_size=self.img_size))\n",
        "            x[j] = img/255\n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = np.array(load_img(path, target_size=self.img_size, color_mode=\"grayscale\"))\n",
        "            # y[j] = np.expand_dims(img, 2)\n",
        "            # # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
        "            # y[j] -= 1\n",
        "            one_hot = img == [0, 85, 170, 255]\n",
        "            y[j] = one_hot\n",
        "            \n",
        "        \n",
        "        #print(y)\n",
        "        return x, y\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3OsroXMQjsk"
      },
      "source": [
        "#train, test, split \n",
        "\n",
        "import random\n",
        "\n",
        "# Split our img paths into a training and a validation set\n",
        "\n",
        "val_samples = 1000\n",
        "# random.Random(1337).shuffle(input_img_paths)\n",
        "# random.Random(1337).shuffle(target_img_paths)\n",
        "train_input_img_paths = input_img_paths[:]\n",
        "train_target_img_paths = target_img_paths[:]\n",
        "# val_input_img_paths = input_img_paths[-val_samples:]\n",
        "# val_target_img_paths = target_img_paths[-val_samples:]\n",
        "val_input_img_paths = val_input_img_paths[:]\n",
        "val_target_img_paths = val_target_img_paths[:]\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "#train data\n",
        "train_gen = oasis_data(\n",
        "    batch_size, img_size, train_input_img_paths, train_target_img_paths\n",
        ")\n",
        "#test data\n",
        "val_gen =  oasis_data(batch_size, img_size, val_input_img_paths, val_target_img_paths)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk_Vhc6JTKWp",
        "outputId": "e8508f7e-7441-4a0f-fa5d-9f5dcdd3a8f1"
      },
      "source": [
        "X_train,y_train = train_gen.__getitem__(1)\n",
        "X_test, y_test = val_gen.__getitem__(1)\n",
        "\n",
        "x_train_scaled = (X_train / 255.0) - 0.5\n",
        "x_test_scaled = (X_test / 255.0) - 0.5\n",
        "\n",
        "data_variance = np.var(X_train / 255.0)\n",
        "\n",
        "print(data_variance)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3179352e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EX4EcS9Wvog",
        "outputId": "4a07386d-6657-4e84-ea51-340d7d1c0102"
      },
      "source": [
        "#train VQ VAE model\n",
        "vqvae_trainer = VQVAETrainer(data_variance, latent_dim=16, num_embeddings=128)\n",
        "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=30)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 585081.3125 - reconstruction_loss: 585081.3125 - vqvae_loss: 0.0110\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 568404.5000 - reconstruction_loss: 568404.5000 - vqvae_loss: 0.0097\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 552499.3125 - reconstruction_loss: 552499.3125 - vqvae_loss: 0.0098\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 537091.6875 - reconstruction_loss: 537091.6875 - vqvae_loss: 0.0124\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 520227.6250 - reconstruction_loss: 520227.5938 - vqvae_loss: 0.0171\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 501273.5000 - reconstruction_loss: 501273.4688 - vqvae_loss: 0.0246\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 479900.4062 - reconstruction_loss: 479900.3750 - vqvae_loss: 0.0349\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 456079.5938 - reconstruction_loss: 456079.5312 - vqvae_loss: 0.0489\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 429444.4062 - reconstruction_loss: 429444.3438 - vqvae_loss: 0.0662\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 399628.9688 - reconstruction_loss: 399628.8750 - vqvae_loss: 0.0874\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 366434.9375 - reconstruction_loss: 366434.8125 - vqvae_loss: 0.1143\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 329989.2500 - reconstruction_loss: 329989.0938 - vqvae_loss: 0.1480\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 290485.4062 - reconstruction_loss: 290485.2188 - vqvae_loss: 0.1904\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 248334.1406 - reconstruction_loss: 248333.8906 - vqvae_loss: 0.2440\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 204469.3438 - reconstruction_loss: 204469.0312 - vqvae_loss: 0.3119\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 160100.2969 - reconstruction_loss: 160099.9062 - vqvae_loss: 0.3978\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 116850.4922 - reconstruction_loss: 116849.9844 - vqvae_loss: 0.5065\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 77540.2656 - reconstruction_loss: 77539.6172 - vqvae_loss: 0.6446\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 45712.9219 - reconstruction_loss: 45712.1016 - vqvae_loss: 0.8192\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 25170.0469 - reconstruction_loss: 25169.0078 - vqvae_loss: 1.0383\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 19268.9668 - reconstruction_loss: 19267.6680 - vqvae_loss: 1.2982\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 28372.7285 - reconstruction_loss: 28371.1680 - vqvae_loss: 1.5613\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 46778.0391 - reconstruction_loss: 46776.3125 - vqvae_loss: 1.7253\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 64935.9375 - reconstruction_loss: 64934.1953 - vqvae_loss: 1.7415\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 75229.5859 - reconstruction_loss: 75227.9375 - vqvae_loss: 1.6455\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 74820.8984 - reconstruction_loss: 74819.4141 - vqvae_loss: 1.4857\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 65130.7227 - reconstruction_loss: 65129.4258 - vqvae_loss: 1.2975\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 50265.0938 - reconstruction_loss: 50263.9883 - vqvae_loss: 1.1072\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 34182.9883 - reconstruction_loss: 34182.0586 - vqvae_loss: 0.9304\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 20161.1484 - reconstruction_loss: 20160.3730 - vqvae_loss: 0.7758\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 10082.5303 - reconstruction_loss: 10081.8857 - vqvae_loss: 0.6441\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 4540.8247 - reconstruction_loss: 4540.2886 - vqvae_loss: 0.5359\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 2984.0537 - reconstruction_loss: 2983.6035 - vqvae_loss: 0.4502\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 4338.6724 - reconstruction_loss: 4338.2900 - vqvae_loss: 0.3821\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 7363.2910 - reconstruction_loss: 7362.9624 - vqvae_loss: 0.3285\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 10887.5439 - reconstruction_loss: 10887.2578 - vqvae_loss: 0.2865\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 14024.6377 - reconstruction_loss: 14024.3838 - vqvae_loss: 0.2537\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 16144.8945 - reconstruction_loss: 16144.6660 - vqvae_loss: 0.2281\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 16983.4961 - reconstruction_loss: 16983.2871 - vqvae_loss: 0.2081\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 16526.3867 - reconstruction_loss: 16526.1934 - vqvae_loss: 0.1925\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 14954.5576 - reconstruction_loss: 14954.3770 - vqvae_loss: 0.1804\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 12613.5850 - reconstruction_loss: 12613.4141 - vqvae_loss: 0.1711\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 9937.1582 - reconstruction_loss: 9936.9941 - vqvae_loss: 0.1638\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 7384.6001 - reconstruction_loss: 7384.4419 - vqvae_loss: 0.1583\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 5363.6089 - reconstruction_loss: 5363.4551 - vqvae_loss: 0.1540\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 4169.5503 - reconstruction_loss: 4169.3999 - vqvae_loss: 0.1505\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 3901.3013 - reconstruction_loss: 3901.1538 - vqvae_loss: 0.1475\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 4421.2012 - reconstruction_loss: 4421.0566 - vqvae_loss: 0.1446\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 5390.7876 - reconstruction_loss: 5390.6460 - vqvae_loss: 0.1416\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 6375.5596 - reconstruction_loss: 6375.4214 - vqvae_loss: 0.1383\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 6995.9268 - reconstruction_loss: 6995.7925 - vqvae_loss: 0.1345\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 7034.0615 - reconstruction_loss: 7033.9312 - vqvae_loss: 0.1303\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 6477.7930 - reconstruction_loss: 6477.6675 - vqvae_loss: 0.1257\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 5506.6641 - reconstruction_loss: 5506.5430 - vqvae_loss: 0.1209\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 4410.8481 - reconstruction_loss: 4410.7324 - vqvae_loss: 0.1159\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 3464.4297 - reconstruction_loss: 3464.3186 - vqvae_loss: 0.1112\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 2849.0432 - reconstruction_loss: 2848.9365 - vqvae_loss: 0.1066\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 2623.5330 - reconstruction_loss: 2623.4304 - vqvae_loss: 0.1025\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 2728.4082 - reconstruction_loss: 2728.3096 - vqvae_loss: 0.0987\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 3029.4382 - reconstruction_loss: 3029.3428 - vqvae_loss: 0.0955\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 3370.0439 - reconstruction_loss: 3369.9512 - vqvae_loss: 0.0927\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 3622.0286 - reconstruction_loss: 3621.9382 - vqvae_loss: 0.0904\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 3706.3450 - reconstruction_loss: 3706.2563 - vqvae_loss: 0.0886\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 3604.5190 - reconstruction_loss: 3604.4319 - vqvae_loss: 0.0871\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 3354.5112 - reconstruction_loss: 3354.4253 - vqvae_loss: 0.0860\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 3031.2605 - reconstruction_loss: 3031.1753 - vqvae_loss: 0.0852\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 2721.9150 - reconstruction_loss: 2721.8306 - vqvae_loss: 0.0846\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 2500.5657 - reconstruction_loss: 2500.4814 - vqvae_loss: 0.0841\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 2408.8381 - reconstruction_loss: 2408.7544 - vqvae_loss: 0.0837\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 2442.7363 - reconstruction_loss: 2442.6531 - vqvae_loss: 0.0833\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 2557.6870 - reconstruction_loss: 2557.6040 - vqvae_loss: 0.0830\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 2688.3430 - reconstruction_loss: 2688.2607 - vqvae_loss: 0.0823\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 2770.6118 - reconstruction_loss: 2770.5303 - vqvae_loss: 0.0816\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 2771.5901 - reconstruction_loss: 2771.5093 - vqvae_loss: 0.0808\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 2692.1521 - reconstruction_loss: 2692.0723 - vqvae_loss: 0.0799\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 2563.2358 - reconstruction_loss: 2563.1570 - vqvae_loss: 0.0788\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 2427.5488 - reconstruction_loss: 2427.4712 - vqvae_loss: 0.0777\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 2322.1768 - reconstruction_loss: 2322.1001 - vqvae_loss: 0.0766\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 2266.8376 - reconstruction_loss: 2266.7622 - vqvae_loss: 0.0756\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 2260.5500 - reconstruction_loss: 2260.4756 - vqvae_loss: 0.0745\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 2285.6455 - reconstruction_loss: 2285.5718 - vqvae_loss: 0.0736\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 2316.6233 - reconstruction_loss: 2316.5505 - vqvae_loss: 0.0728\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 2331.5310 - reconstruction_loss: 2331.4590 - vqvae_loss: 0.0721\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 2319.5464 - reconstruction_loss: 2319.4749 - vqvae_loss: 0.0715\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 2281.9360 - reconstruction_loss: 2281.8650 - vqvae_loss: 0.0711\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 2229.6084 - reconstruction_loss: 2229.5376 - vqvae_loss: 0.0707\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 2178.2739 - reconstruction_loss: 2178.2036 - vqvae_loss: 0.0704\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 2142.6951 - reconstruction_loss: 2142.6250 - vqvae_loss: 0.0701\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 2129.2803 - reconstruction_loss: 2129.2104 - vqvae_loss: 0.0698\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 2135.2761 - reconstruction_loss: 2135.2065 - vqvae_loss: 0.0695\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 2150.1543 - reconstruction_loss: 2150.0852 - vqvae_loss: 0.0692\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 2160.6904 - reconstruction_loss: 2160.6216 - vqvae_loss: 0.0688\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 2157.4465 - reconstruction_loss: 2157.3782 - vqvae_loss: 0.0684\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 2138.8118 - reconstruction_loss: 2138.7439 - vqvae_loss: 0.0679\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 2109.5884 - reconstruction_loss: 2109.5210 - vqvae_loss: 0.0674\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2076.0728 - reconstruction_loss: 2076.0059 - vqvae_loss: 0.0669\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 2046.4645 - reconstruction_loss: 2046.3982 - vqvae_loss: 0.0663\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 2025.8657 - reconstruction_loss: 2025.7999 - vqvae_loss: 0.0658\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 2013.0449 - reconstruction_loss: 2012.9796 - vqvae_loss: 0.0653\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 2004.0267 - reconstruction_loss: 2003.9619 - vqvae_loss: 0.0648\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa946986a90>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kf6GabqPM54",
        "outputId": "45152bca-a127-41e0-951c-cdae29f6f10e"
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJcgUrEdWe1P"
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}