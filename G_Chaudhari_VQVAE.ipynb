{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "G_Chaudhari VQVAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAKh2tBvbObwb1ymAiA5nh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GCioa123/PatternFlow/blob/topic-recognition/G_Chaudhari_VQVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTb4lLSuWDRe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf"
      ],
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6rAw4V2IYA8",
        "outputId": "7060cd4e-1ad4-433a-b05a-fdccd7849d45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xep4-xdNMMj"
      },
      "source": [
        "import os\n",
        "\n",
        "#Loading the data\n",
        "\n",
        "input_train_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_train/' #this you have give your seg_train folder path\n",
        "target_train_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_seg_train/' #seg_val folder path\n",
        "input_val_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_validate/' #this you have give your seg_train folder path\n",
        "target_val_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_seg_validate/' #seg_val folder path\n"
      ],
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mocffPMdPb_-",
        "outputId": "53e1668c-ceec-4f68-ac3c-1ae8866f4028"
      },
      "source": [
        "# Extract data to train and test data sets\n",
        "img_size = (256, 256)\n",
        "num_classes = 4\n",
        "batch_size = 3\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_train_dir, fname)\n",
        "        for fname in os.listdir(input_train_dir)\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_train_dir, fname)\n",
        "        for fname in os.listdir(target_train_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_val_dir, fname)\n",
        "        for fname in os.listdir(input_val_dir)\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "val_target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_val_dir, fname)\n",
        "        for fname in os.listdir(target_val_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths))\n",
        "\n",
        "# for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
        "#     print(input_path, \"|\", target_path)"
      ],
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PClDjJN7Ncxi"
      },
      "source": [
        "#vectoriser\n",
        "\n",
        "class VectorQuantizer(layers.Layer):\n",
        "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.beta = (\n",
        "            beta  # This parameter is best kept between [0.25, 2] as per the paper.\n",
        "        )\n",
        "\n",
        "        # Initialize the embeddings which we will quantize.\n",
        "        w_init = tf.random_uniform_initializer()\n",
        "        self.embeddings = tf.Variable(\n",
        "            initial_value=w_init(\n",
        "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
        "            ),\n",
        "            trainable=True,\n",
        "            name=\"embeddings_vqvae\",\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        # Calculate the input shape of the inputs and\n",
        "        # then flatten the inputs keeping `embedding_dim` intact.\n",
        "        input_shape = tf.shape(x)\n",
        "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
        "\n",
        "        # Quantization.\n",
        "        encoding_indices = self.get_code_indices(flattened)\n",
        "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
        "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
        "        quantized = tf.reshape(quantized, input_shape)\n",
        "\n",
        "        # Calculate vector quantization loss and add that to the layer. You can learn more\n",
        "        # about adding losses to different layers here:\n",
        "        # https://keras.io/guides/making_new_layers_and_models_via_subclassing/. Check\n",
        "        # the original paper to get a handle on the formulation of the loss function.\n",
        "        commitment_loss = self.beta * tf.reduce_mean(\n",
        "            (tf.stop_gradient(quantized) - x) ** 2\n",
        "        )\n",
        "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
        "        self.add_loss(commitment_loss + codebook_loss)\n",
        "\n",
        "        # Straight-through estimator.\n",
        "        quantized = x + tf.stop_gradient(quantized - x)\n",
        "        return quantized\n",
        "\n",
        "    def get_code_indices(self, flattened_inputs):\n",
        "        # Calculate L2-normalized distance between the inputs and the codes.\n",
        "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
        "        distances = (\n",
        "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
        "            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
        "            - 2 * similarity\n",
        "        )\n",
        "\n",
        "        # Derive the indices for minimum distances.\n",
        "        encoding_indices = tf.argmin(distances, axis=1)\n",
        "        return encoding_indices"
      ],
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23s4Qw1dNant"
      },
      "source": [
        "#encoder \n",
        "def get_encoder(latent_dim=32):\n",
        "    encoder_inputs = keras.Input(shape=(256, 256, 3))\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        encoder_inputs\n",
        "    )\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    encoder_outputs = layers.Conv2D(latent_dim, 3, padding=\"same\")(x)\n",
        "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n"
      ],
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8K2fEzwNep0"
      },
      "source": [
        "#decoder\n",
        "def get_decoder(latent_dim=32):\n",
        "    latent_inputs = keras.Input(shape=get_encoder().output.shape[1:])\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "        latent_inputs\n",
        "    )\n",
        "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(3, 3, padding=\"same\")(x)\n",
        "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
      ],
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my_o9U8PNgZ7",
        "outputId": "15677c74-e83c-4479-8013-14f0bac9d3f3"
      },
      "source": [
        "#Stand-alone VQ-VAE\n",
        "def get_vqvae(latent_dim=32, num_embeddings=64):\n",
        "    vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n",
        "    encoder = get_encoder(latent_dim)\n",
        "    decoder = get_decoder(latent_dim)\n",
        "    inputs = keras.Input(shape=(256, 256, 3))\n",
        "    encoder_outputs = encoder(inputs)\n",
        "    quantized_latents = vq_layer(encoder_outputs)\n",
        "    reconstructions = decoder(quantized_latents)\n",
        "    return keras.Model(inputs, reconstructions, name=\"vq_vae\")\n",
        "\n",
        "\n",
        "get_vqvae().summary()\n"
      ],
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vq_vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_252 (InputLayer)      [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 64, 64, 32)        37856     \n",
            "                                                                 \n",
            " vector_quantizer (VectorQua  (None, 64, 64, 32)       2048      \n",
            " ntizer)                                                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 256, 256, 3)       37827     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,731\n",
            "Trainable params: 77,731\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdRnn0YhPM_f"
      },
      "source": [
        "#VQ-VAE Trainer\n",
        "class VQVAETrainer(keras.models.Model):\n",
        "    def __init__(self, train_variance, latent_dim=32, num_embeddings=128, **kwargs):\n",
        "        super(VQVAETrainer, self).__init__(**kwargs)\n",
        "        self.train_variance = train_variance\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "\n",
        "        self.vqvae = get_vqvae(self.latent_dim, self.num_embeddings)\n",
        "\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.vq_loss_tracker = keras.metrics.Mean(name=\"vq_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.vq_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, x):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Outputs from the VQ-VAE.\n",
        "            # og code delete - reconstructions = self.vqvae(x)\n",
        "            tmp_result = self.vqvae(x) #change tmp\n",
        "\n",
        "            #Calculate image difference using SSIM\n",
        "  \n",
        "            # print(x.shape)\n",
        "            # print(tf.expand_dims(x,-1).shape)\n",
        "            # print(tmp_result.shape)\n",
        "            #change\n",
        "\n",
        "            \n",
        "\n",
        "            img_diff = 1 - (tf.image.ssim(x, tmp_result, 3))\n",
        "\n",
        "\n",
        "            # Calculate the losses.\n",
        "            reconstruction_loss = (\n",
        "                tf.reduce_mean((x - tmp_result) ** 2) / self.train_variance\n",
        "            )\n",
        "            total_loss = img_diff + sum(self.vqvae.losses)\n",
        "\n",
        "        # Backpropagation.\n",
        "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
        "\n",
        "        # Loss tracking.\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
        "\n",
        "        # Log results.\n",
        "        return {\n",
        "            \"loss(SSIM)\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
        "        }\n"
      ],
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jukvz4ZVRMKZ"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "\n",
        "class oasis_data(keras.utils.Sequence):\n",
        "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = np.array(load_img(path, target_size=self.img_size))\n",
        "            x[j] = img/255\n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = np.array(load_img(path, target_size=self.img_size, color_mode=\"grayscale\"))\n",
        "            # y[j] = np.expand_dims(img, 2)\n",
        "            # # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
        "            # y[j] -= 1\n",
        "            one_hot = img == [0, 85, 170, 255]\n",
        "            y[j] = one_hot\n",
        "            \n",
        "        \n",
        "        #print(y)\n",
        "        return x, y\n"
      ],
      "execution_count": 430,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3OsroXMQjsk"
      },
      "source": [
        "#train, test, split \n",
        "\n",
        "import random\n",
        "\n",
        "# Split our img paths into a training and a validation set\n",
        "\n",
        "val_samples = 1000\n",
        "# random.Random(1337).shuffle(input_img_paths)\n",
        "# random.Random(1337).shuffle(target_img_paths)\n",
        "train_input_img_paths = input_img_paths[:]\n",
        "train_target_img_paths = target_img_paths[:]\n",
        "# val_input_img_paths = input_img_paths[-val_samples:]\n",
        "# val_target_img_paths = target_img_paths[-val_samples:]\n",
        "val_input_img_paths = val_input_img_paths[:]\n",
        "val_target_img_paths = val_target_img_paths[:]\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "#train data\n",
        "train_gen = oasis_data(\n",
        "    batch_size, img_size, train_input_img_paths, train_target_img_paths\n",
        ")\n",
        "#test data\n",
        "val_gen =  oasis_data(batch_size, img_size, val_input_img_paths, val_target_img_paths)"
      ],
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk_Vhc6JTKWp",
        "outputId": "ff3f456d-4536-4b9e-e909-ccf46b78925e"
      },
      "source": [
        "X_train,y_train = train_gen.__getitem__(1)\n",
        "X_test, y_test = val_gen.__getitem__(1)\n",
        "\n",
        "# dimension reduction to make images the same shape\n",
        "# X_train = tf.expand_dims(X_train, axis=1)\n",
        "# X_test = tf.expand_dims(X_test, axis=1) \n",
        "\n",
        "x_train_scaled = (X_train / 255.0) - 0.5\n",
        "x_test_scaled = (X_test / 255.0) - 0.5\n",
        "\n",
        "data_variance = np.var(X_train / 255.0)\n",
        "\n",
        "print(data_variance)"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3179352e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EX4EcS9Wvog",
        "outputId": "0283d680-fd98-4391-f04c-80dc6f2476f2"
      },
      "source": [
        "#train VQ VAE model\n",
        "vqvae_trainer = VQVAETrainer(data_variance, latent_dim=32, num_embeddings=256)\n",
        "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128)\n"
      ],
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss(SSIM): 1.0232 - reconstruction_loss: 584855.7500 - vqvae_loss: 0.0148\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.0015 - reconstruction_loss: 571589.7500 - vqvae_loss: 0.0162\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.9864 - reconstruction_loss: 560090.9375 - vqvae_loss: 0.0213\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.9756 - reconstruction_loss: 548251.1875 - vqvae_loss: 0.0315\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.9686 - reconstruction_loss: 535068.1875 - vqvae_loss: 0.0480\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.9686 - reconstruction_loss: 519816.0000 - vqvae_loss: 0.0752\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.9789 - reconstruction_loss: 501956.8750 - vqvae_loss: 0.1176\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.0062 - reconstruction_loss: 480843.2188 - vqvae_loss: 0.1828\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.0595 - reconstruction_loss: 456213.6250 - vqvae_loss: 0.2799\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.1517 - reconstruction_loss: 427698.3125 - vqvae_loss: 0.4219\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.3017 - reconstruction_loss: 395152.8438 - vqvae_loss: 0.6272\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.5390 - reconstruction_loss: 358599.6562 - vqvae_loss: 0.9241\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.9045 - reconstruction_loss: 318532.7812 - vqvae_loss: 1.3517\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 2.4561 - reconstruction_loss: 276054.5312 - vqvae_loss: 1.9666\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 3.2710 - reconstruction_loss: 232603.3594 - vqvae_loss: 2.8451\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 4.4466 - reconstruction_loss: 189963.5156 - vqvae_loss: 4.0849\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 6.0866 - reconstruction_loss: 149773.1094 - vqvae_loss: 5.7892\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 8.2641 - reconstruction_loss: 113383.2344 - vqvae_loss: 8.0299\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 10.9147 - reconstruction_loss: 81766.1406 - vqvae_loss: 10.7373\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 13.7221 - reconstruction_loss: 55619.2812 - vqvae_loss: 13.5866\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 15.8071 - reconstruction_loss: 35479.1680 - vqvae_loss: 15.6957\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 16.2547 - reconstruction_loss: 21673.6777 - vqvae_loss: 16.1581\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 15.2001 - reconstruction_loss: 14015.0918 - vqvae_loss: 15.1191\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 13.2808 - reconstruction_loss: 12015.5078 - vqvae_loss: 13.2182\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 11.0401 - reconstruction_loss: 15064.0967 - vqvae_loss: 10.9942\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 8.8317 - reconstruction_loss: 22383.0957 - vqvae_loss: 8.7936\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 6.8467 - reconstruction_loss: 32349.4102 - vqvae_loss: 6.8050\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 5.1625 - reconstruction_loss: 42499.9727 - vqvae_loss: 5.1111\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 3.7931 - reconstruction_loss: 50550.5039 - vqvae_loss: 3.7345\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 2.7222 - reconstruction_loss: 55683.0898 - vqvae_loss: 2.6600\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.9142 - reconstruction_loss: 57859.4102 - vqvae_loss: 1.8496\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 1.3281 - reconstruction_loss: 57591.3438 - vqvae_loss: 1.2629\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.9106 - reconstruction_loss: 55353.4844 - vqvae_loss: 0.8485\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.6173 - reconstruction_loss: 51457.8086 - vqvae_loss: 0.5627\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.4152 - reconstruction_loss: 46237.2578 - vqvae_loss: 0.3695\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.2799 - reconstruction_loss: 39886.3164 - vqvae_loss: 0.2421\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.1911 - reconstruction_loss: 32657.9668 - vqvae_loss: 0.1591\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.1330 - reconstruction_loss: 25105.7637 - vqvae_loss: 0.1058\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0938 - reconstruction_loss: 17844.1934 - vqvae_loss: 0.0724\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0674 - reconstruction_loss: 11642.1875 - vqvae_loss: 0.0516\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0507 - reconstruction_loss: 7752.5601 - vqvae_loss: 0.0389\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0395 - reconstruction_loss: 5076.7612 - vqvae_loss: 0.0315\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0451 - reconstruction_loss: 9374.3945 - vqvae_loss: 0.0273\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.2310 - reconstruction_loss: 149943.0469 - vqvae_loss: 0.0228\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.2191 - reconstruction_loss: 145150.4844 - vqvae_loss: 0.0193\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.1972 - reconstruction_loss: 133534.2031 - vqvae_loss: 0.0164\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.1695 - reconstruction_loss: 117162.5391 - vqvae_loss: 0.0140\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.1387 - reconstruction_loss: 97657.2578 - vqvae_loss: 0.0120\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.1090 - reconstruction_loss: 76279.3359 - vqvae_loss: 0.0104\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0833 - reconstruction_loss: 55473.3789 - vqvae_loss: 0.0092\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0631 - reconstruction_loss: 36810.8242 - vqvae_loss: 0.0083\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0485 - reconstruction_loss: 21704.3867 - vqvae_loss: 0.0078\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0381 - reconstruction_loss: 10973.4756 - vqvae_loss: 0.0076\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0301 - reconstruction_loss: 4703.9912 - vqvae_loss: 0.0076\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0253 - reconstruction_loss: 2246.1201 - vqvae_loss: 0.0078\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0228 - reconstruction_loss: 3058.6455 - vqvae_loss: 0.0081\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0247 - reconstruction_loss: 6232.6152 - vqvae_loss: 0.0084\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0635 - reconstruction_loss: 37516.8047 - vqvae_loss: 0.0081\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0587 - reconstruction_loss: 39148.0977 - vqvae_loss: 0.0078\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0510 - reconstruction_loss: 37960.0352 - vqvae_loss: 0.0073\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0431 - reconstruction_loss: 35545.1406 - vqvae_loss: 0.0069\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0434 - reconstruction_loss: 26283.2715 - vqvae_loss: 0.0062\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0434 - reconstruction_loss: 26977.1699 - vqvae_loss: 0.0055\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0388 - reconstruction_loss: 26098.8027 - vqvae_loss: 0.0050\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0317 - reconstruction_loss: 23653.7578 - vqvae_loss: 0.0047\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0109 - reconstruction_loss: 2514.8257 - vqvae_loss: 0.0046\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0210 - reconstruction_loss: 12725.0205 - vqvae_loss: 0.0044\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0213 - reconstruction_loss: 13427.5449 - vqvae_loss: 0.0042\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0210 - reconstruction_loss: 12916.8799 - vqvae_loss: 0.0040\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0198 - reconstruction_loss: 12017.0771 - vqvae_loss: 0.0037\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0180 - reconstruction_loss: 10504.5967 - vqvae_loss: 0.0035\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0160 - reconstruction_loss: 8832.0078 - vqvae_loss: 0.0032\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0131 - reconstruction_loss: 7168.3618 - vqvae_loss: 0.0030\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0101 - reconstruction_loss: 5618.6543 - vqvae_loss: 0.0028\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0081 - reconstruction_loss: 4285.2705 - vqvae_loss: 0.0027\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0063 - reconstruction_loss: 3218.6313 - vqvae_loss: 0.0026\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0046 - reconstruction_loss: 2473.2991 - vqvae_loss: 0.0025\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0038 - reconstruction_loss: 2079.5320 - vqvae_loss: 0.0025\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0039 - reconstruction_loss: 2020.0513 - vqvae_loss: 0.0025\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0052 - reconstruction_loss: 2244.1008 - vqvae_loss: 0.0024\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0058 - reconstruction_loss: 2675.5911 - vqvae_loss: 0.0023\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0061 - reconstruction_loss: 3228.0701 - vqvae_loss: 0.0022\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0061 - reconstruction_loss: 3812.3186 - vqvae_loss: 0.0021\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0061 - reconstruction_loss: 4353.6987 - vqvae_loss: 0.0019\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0060 - reconstruction_loss: 4786.2554 - vqvae_loss: 0.0017\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0058 - reconstruction_loss: 5041.0034 - vqvae_loss: 0.0015\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0056 - reconstruction_loss: 5098.6304 - vqvae_loss: 0.0013\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0058 - reconstruction_loss: 4944.1006 - vqvae_loss: 0.0012\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0057 - reconstruction_loss: 4605.1572 - vqvae_loss: 0.0011\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0053 - reconstruction_loss: 4095.4509 - vqvae_loss: 9.8280e-04\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0052 - reconstruction_loss: 3569.6995 - vqvae_loss: 9.1481e-04\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0044 - reconstruction_loss: 3112.1653 - vqvae_loss: 8.6922e-04\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0035 - reconstruction_loss: 2721.8311 - vqvae_loss: 8.4183e-04\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0031 - reconstruction_loss: 2477.8162 - vqvae_loss: 8.2965e-04\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0027 - reconstruction_loss: 2396.7563 - vqvae_loss: 8.2901e-04\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0025 - reconstruction_loss: 2458.9673 - vqvae_loss: 8.3588e-04\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0104 - reconstruction_loss: 8202.7930 - vqvae_loss: 7.8456e-04\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0103 - reconstruction_loss: 8620.6182 - vqvae_loss: 7.2368e-04\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0098 - reconstruction_loss: 8598.3789 - vqvae_loss: 6.5960e-04\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 2s 2s/step - loss(SSIM): 0.0086 - reconstruction_loss: 8137.7983 - vqvae_loss: 6.0565e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa947121a90>"
            ]
          },
          "metadata": {},
          "execution_count": 438
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kf6GabqPM54",
        "outputId": "a684872b-1373-4129-9615-4bb110cf2a16"
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJcgUrEdWe1P"
      },
      "source": [
        ""
      ],
      "execution_count": 434,
      "outputs": []
    }
  ]
}