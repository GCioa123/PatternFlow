{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VQVAE_main_G_Chaudhari.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM90DP9VRn8kSsyXizJFEOm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GCioa123/PatternFlow/blob/topic-recognition/VQVAE_main_G_Chaudhari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBkYetLdJJl6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwCsCMoFGjf_",
        "outputId": "2b8c3c7c-918a-457e-a6c8-7122b735b231"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU5XkDegIarx"
      },
      "source": [
        "sys.path.append('/content/gdrive/My Drive/recog_report_scripts/')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve8xX95QHBzP"
      },
      "source": [
        "from oasis_data import oasis_data\n",
        "from vqvae_get import *\n",
        "from vqvae_trainer import *"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfOEhWCClzfn"
      },
      "source": [
        "def show_subplot(original, reconstructed):\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(original.squeeze() + 0.5)\n",
        "  plt.title(\"Original\")\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(reconstructed.squeeze() + 0.5)\n",
        "  plt.title(\"Reconstructed\")\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def main():\n",
        "\n",
        "  input_train_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_train/' #this you have give your seg_train folder path\n",
        "  target_train_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_seg_train/' #seg_val folder path\n",
        "  input_val_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_validate/' #this you have give your seg_train folder path\n",
        "  target_val_dir = 'gdrive/My Drive/keras_png_slices_data/keras_png_slices_data/keras_png_slices_seg_validate/' #seg_val folder path\n",
        "\n",
        "  # Extract data to train and test data sets\n",
        "  img_size = (256, 256)\n",
        "  num_classes = 4\n",
        "  batch_size = 1\n",
        "\n",
        "  input_img_paths = sorted(\n",
        "      [\n",
        "          os.path.join(input_train_dir, fname)\n",
        "          for fname in os.listdir(input_train_dir)\n",
        "          if fname.endswith(\".png\")\n",
        "      ]\n",
        "  )\n",
        "  target_img_paths = sorted(\n",
        "      [\n",
        "          os.path.join(target_train_dir, fname)\n",
        "          for fname in os.listdir(target_train_dir)\n",
        "          if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  val_input_img_paths = sorted(\n",
        "      [\n",
        "          os.path.join(input_val_dir, fname)\n",
        "          for fname in os.listdir(input_val_dir)\n",
        "          if fname.endswith(\".png\")\n",
        "      ]\n",
        "  )\n",
        "  val_target_img_paths = sorted(\n",
        "      [\n",
        "          os.path.join(target_val_dir, fname)\n",
        "          for fname in os.listdir(target_val_dir)\n",
        "          if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # print(\"Number of samples:\", len(input_img_paths))\n",
        "\n",
        "  #Load train and test data from OASIS dataset.\n",
        "\n",
        "\n",
        "  train_input_img_paths = input_img_paths[:]\n",
        "  train_target_img_paths = target_img_paths[:]\n",
        "  val_input_img_paths = val_input_img_paths[:]\n",
        "  val_target_img_paths = val_target_img_paths[:]\n",
        "\n",
        "  print(\"hello i work 1\")\n",
        "\n",
        "\n",
        "  # Loading training data \n",
        "  train_gen = oasis_data(\n",
        "      batch_size, img_size, train_input_img_paths, train_target_img_paths\n",
        "  )\n",
        "  # Loading testing data\n",
        "  val_gen =  oasis_data(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n",
        "\n",
        "  X_train = tf.convert_to_tensor([tf.reshape(tf.image.resize(train_gen.__getitem__(i),[80,80]),[80,80,3]) for i in range(train_gen.__len__())])\n",
        "  X_test = tf.convert_to_tensor([tf.reshape(tf.image.resize(val_gen.__getitem__(i),[80,80]),[80,80,3]) for i in range(val_gen.__len__())])\n",
        "  data_variance = np.var(X_train / 255.0)\n",
        "\n",
        "  print(\"hello i work\")\n",
        "\n",
        "  #train VQ VAE model\n",
        "  vqvae_trainer = VQVAETrainer(data_variance, latent_dim=32, num_embeddings=128)\n",
        "  vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "  vqvae_trainer.fit(X_train, epochs=10)\n",
        "\n",
        "  trained_vqvae_model = vqvae_trainer.vqvae\n",
        "  idx = np.random.choice(len(X_test), 10)\n",
        "  test_images = X_test[idx]\n",
        "  reconstructions_test = trained_vqvae_model.predict(test_images)\n",
        "\n",
        "  for test_image, reconstructed_image in zip(test_images, reconstructions_test):\n",
        "      show_subplot(test_image, reconstructed_image)\n",
        "\n",
        "  #Visualising the discrete codes \n",
        "\n",
        "  encoder = vqvae_trainer.vqvae.get_layer(\"encoder\")\n",
        "  quantizer = vqvae_trainer.vqvae.get_layer(\"vector_quantizer\")\n",
        "\n",
        "  encoded_outputs = encoder.predict(test_images)\n",
        "  flat_enc_outputs = encoded_outputs.reshape(-1, encoded_outputs.shape[-1])\n",
        "  codebook_indices = quantizer.get_code_indices(flat_enc_outputs)\n",
        "  codebook_indices = codebook_indices.numpy().reshape(encoded_outputs.shape[:-1])\n",
        "\n",
        "  for i in range(len(test_images)):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(test_images[i].squeeze() + 0.5)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(codebook_indices[i])\n",
        "    plt.title(\"Code\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "  # evaluating the model performance with test dataset\n",
        "  # trained_vqvae_model = vqvae_trainer.vqvae\n",
        "  reconstructions_test = trained_vqvae_model.predict(X_test)\n",
        "  ssim_score = tf.reduce_mean(tf.image.ssim(X_test, reconstructions_test,1))\n",
        "  print(\"Average SSIM is: \", ssim_score)\n",
        "  \n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbTKLT11ojc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e740bdfb-e881-4fda-c0a7-237111d72889"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello i work 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73wNQ7q5ASLD"
      },
      "source": [
        "while True: pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
